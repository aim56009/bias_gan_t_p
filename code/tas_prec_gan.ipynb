{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aim56009/Bias_GAN/blob/master/code/tas_prec_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3yHWmlizCSY"
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_colab = False\n",
    "\n",
    "if is_colab==False:\n",
    "    colab_path = \"bias_gan_t_p/\"\n",
    "else:\n",
    "    colab_path = \"/content/gdrive/MyDrive/bias_gan_t_p/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrend_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UtBBY2Vx4kVx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngpu_info = !nvidia-smi\\ngpu_info = '\\n'.join(gpu_info)\\nif gpu_info.find('failed') >= 0:\\n  print('Not connected to a GPU')\\nelse:\\n  print(gpu_info)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab == True:\n",
    "    !git clone https://github.com/aim56009/bias_gan_t_p.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yg_fJ3Fi0rzt"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pytorch_lightning\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "!pip install basemap\n",
    "!pip install importlib-metadata==4.0.1\n",
    "!pip install xarray==0.18.1\n",
    "!pip install torchvision\n",
    "!pip install cftime\n",
    "#!pip install netcdf4  ###this is sometimes needed.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab == False:\n",
    "    import os\n",
    "    os.chdir('/dss/dsshome1/0D/ge74xuf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ctpYd5RO0GJ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import argparse\n",
    "import pathlib\n",
    "import cv2\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "from bias_gan_t_p.code.src.model import CycleGAN, Generator, DataModule                     \n",
    "\n",
    "from bias_gan_t_p.code.src.data import TestData, CycleDataset\n",
    "from bias_gan_t_p.code.src.utils import get_version, set_environment, get_checkpoint_path, save_config, log_transform, inv_norm_transform, inv_log_transform, inv_norm_minus1_to_plus1_transform, norm_minus1_to_plus1_transform \n",
    "from bias_gan_t_p.code.src.plots import PlotAnalysis, plot_basemap\n",
    "from bias_gan_t_p.code.src.callbacks import get_cycle_gan_callbacks, MAE_Callback\n",
    "from bias_gan_t_p.code.src.inference import Inference, EvaluateCheckpoints, create_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDZR-hows48Z"
   },
   "source": [
    "# Main training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtINdQOafvRG"
   },
   "source": [
    "## define MAE callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KpchPItBC6E6"
   },
   "outputs": [],
   "source": [
    "class MAE_Callback(Callback):\n",
    "    def __init__(self,logger,checkpoint_path,config, validation=True, lat_mean=False, plt_hist=False):\n",
    "        self.MAE_list_pr = []\n",
    "        self.MAE_list_t = []\n",
    "        self.logger = logger\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.config = config\n",
    "        self.version = get_version(config.date,config.time)\n",
    "        self.validation = validation\n",
    "        self.lat_mean = lat_mean\n",
    "        self.plt_hist = plt_hist\n",
    "        \n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        checkpoint_files = glob.glob(str(self.checkpoint_path) + '/*.ckpt')\n",
    "        if not checkpoint_files:\n",
    "            test_data_ = None\n",
    "        else:\n",
    "            last_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
    "            data = EvaluateCheckpoints(checkpoint_path=last_checkpoint, config_path=self.config.config_path + self.version + \"/config_model.json\", save_model=True,validation=self.validation, version=self.version)\n",
    "            _, reconstruction_data = data.run()\n",
    "            test_data_ = data.get_test_data()\n",
    "\n",
    "\n",
    "        if test_data_ is None or not test_data_:\n",
    "            print(\"No test data available.\")\n",
    "            return\n",
    "\n",
    "        gan_data = getattr(test_data_, 'gan')\n",
    "        era5_data = getattr(test_data_, \"era5\")\n",
    "        \n",
    "        bias_pr = gan_data.precipitation.mean('time') - era5_data.precipitation.mean('time') \n",
    "        print(\"GAN-OBS precipitation\",f\" \\t \\t MAE: {abs(bias_pr).values.mean():2.3f} [mm/d]\")\n",
    "        self.MAE_list_pr.append(abs(bias_pr).values.mean())\n",
    "        print(\"MAE_list precipitation:\",self.MAE_list_pr)\n",
    "        self.log('MAE p', abs(bias_pr).values.mean())\n",
    "        print(\"\")\n",
    "        bias_t = gan_data.tas.mean('time') - era5_data.tas.mean('time') \n",
    "        print(\"GAN-OBS tas\",f\" \\t \\t MAE: {abs(bias_t).values.mean():2.3f} [K]\")\n",
    "        self.MAE_list_t.append(abs(bias_t).values.mean())\n",
    "        print(\"MAE_list tas:\",self.MAE_list_t)\n",
    "        self.log('MAE t', abs(bias_t).values.mean())\n",
    "        print(\"\")\n",
    "\n",
    "        if test_data_ is not None and self.lat_mean==True:\n",
    "            data_era5_pr = era5_data.precipitation.mean(dim=(\"longitude\", \"time\"))\n",
    "            data_era5_t = era5_data.tas.mean(dim=(\"lon\", \"time\"))\n",
    "            \n",
    "            data_gan_pr= gan_data.precipitation.mean(dim=(\"longitude\", \"time\"))\n",
    "            data_gan_t= gan_data.tas.mean(dim=(\"longitude\", \"time\"))\n",
    "            \n",
    "            plt.figure()\n",
    "            \n",
    "            plt.plot(data_gan_pr.latitude, data_gan_pr.data,\n",
    "                      label=\"gan precipitation\",\n",
    "                      alpha=0.9,\n",
    "                      linestyle='-',\n",
    "                      linewidth=2,\n",
    "                      color=\"red\")\n",
    "            \n",
    "            plt.plot(data_era5_pr.latitude, data_era5_pr.data,\n",
    "                      label=\"era5 precipitation\",\n",
    "                      alpha=1,\n",
    "                      linestyle='--',\n",
    "                      linewidth=2,\n",
    "                      color=\"black\")\n",
    "            \n",
    "            #plt.ylim(0,3)\n",
    "            plt.xlim(25,58)\n",
    "            plt.xlabel('Latitude')\n",
    "            plt.ylabel('Mean precipitation [mm/d]')\n",
    "            plt.grid()\n",
    "            plt.legend(loc='upper right')  \n",
    "            \n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            im = Image.open(buf)\n",
    "            img = torchvision.transforms.ToTensor()(im)\n",
    "            \n",
    "            self.logger.experiment.add_image(f\"latitudinal_mean precipitation\", img, trainer.current_epoch)\n",
    "            \n",
    "            \n",
    "            ###\n",
    "            plt.figure()\n",
    "            \n",
    "            plt.plot(data_gan_t.latitude, data_gan_t.data,\n",
    "                      label=\"gan temperature\",\n",
    "                      alpha=0.9,\n",
    "                      linestyle='-',\n",
    "                      linewidth=2,\n",
    "                      color=\"red\")\n",
    "            \n",
    "            plt.plot(data_era5_t.lat, data_era5_t.data,\n",
    "                      label=\"era5 temperature\",\n",
    "                      alpha=1,\n",
    "                      linestyle='--',\n",
    "                      linewidth=2,\n",
    "                      color=\"black\")\n",
    "            \n",
    "            #plt.ylim(0,3)\n",
    "            plt.xlim(25,58)\n",
    "            plt.xlabel('Latitude')\n",
    "            plt.ylabel('Mean temperature [K]')\n",
    "            plt.grid()\n",
    "            plt.legend(loc='upper right')\n",
    "            #plt.show()\n",
    "            ###\n",
    "            \n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            im = Image.open(buf)\n",
    "            img = torchvision.transforms.ToTensor()(im)\n",
    "            \n",
    "            self.logger.experiment.add_image(f\"latitudinal_mean temperature\", img, trainer.current_epoch)\n",
    "\n",
    "        if test_data_ is not None and self.plt_hist==True:\n",
    "            data_gan_pr = getattr(test_data_, \"gan\").precipitation.values.flatten()\n",
    "            data_era5_pr = getattr(test_data_, \"era5\").precipitation.values.flatten()\n",
    "            plt.figure()\n",
    "            _ = plt.hist(data_gan_pr,\n",
    "                        bins=100,\n",
    "                        histtype='step',\n",
    "                        log=True,\n",
    "                        label=\"gan\",\n",
    "                        alpha=0.9,\n",
    "                        density=True,\n",
    "                        linewidth=2,\n",
    "                        color=\"red\")\n",
    "            \n",
    "            _ = plt.hist(data_era5_pr,\n",
    "                        bins=100,\n",
    "                        histtype='step',\n",
    "                        log=True,\n",
    "                        label=\"era5\",\n",
    "                        alpha=1,\n",
    "                        density=True,\n",
    "                        linewidth=2,\n",
    "                        color=\"black\")\n",
    "\n",
    "            plt.xlabel('Precipitation [mm/d]')\n",
    "            plt.ylabel('Histogram')\n",
    "            #plt.xlim(0,400)\n",
    "            plt.grid()\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "            #plt.show()\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            im_ = Image.open(buf)\n",
    "            img_ = torchvision.transforms.ToTensor()(im_)\n",
    "            \n",
    "            self.logger.experiment.add_image(f\"histogram precipitation\", img_, trainer.current_epoch)\n",
    "            \n",
    "            \n",
    "            data_gan_t = getattr(test_data_, \"gan\").tas.values.flatten()\n",
    "            data_era5_t = getattr(test_data_, \"era5\").tas.values.flatten()\n",
    "            plt.figure()\n",
    "            _ = plt.hist(data_gan_t,\n",
    "                        bins=100,\n",
    "                        histtype='step',\n",
    "                        log=True,\n",
    "                        label=\"gan\",\n",
    "                        alpha=0.9,\n",
    "                        density=True,\n",
    "                        linewidth=2,\n",
    "                        color=\"red\")\n",
    "            \n",
    "            _ = plt.hist(data_era5_t,\n",
    "                        bins=100,\n",
    "                        histtype='step',\n",
    "                        log=True,\n",
    "                        label=\"era5\",\n",
    "                        alpha=1,\n",
    "                        density=True,\n",
    "                        linewidth=2,\n",
    "                        color=\"black\")\n",
    "\n",
    "            plt.xlabel('Temperature [K]')\n",
    "            plt.ylabel('Histogram')\n",
    "            #plt.xlim(0,400)\n",
    "            plt.grid()\n",
    "            plt.legend(loc='upper right')\n",
    "\n",
    "            #plt.show()\n",
    "            buf = BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            im_ = Image.open(buf)\n",
    "            img_ = torchvision.transforms.ToTensor()(im_)\n",
    "            \n",
    "            self.logger.experiment.add_image(f\"histogram\", img_, trainer.current_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO0_lUBIfzaH"
   },
   "source": [
    "## Train Cycle GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "efWHPrX2Ck9K"
   },
   "outputs": [],
   "source": [
    "def train_cycle_gan(config, pretrain_path=False,validation=True,track_lat_mean=False,plt_hist=False ):\n",
    "    \"\"\" Main routing to train the Cycle GAN \"\"\"\n",
    "\n",
    "    config = Config()\n",
    "    global version\n",
    "    version = get_version(config.date,config.time)\n",
    "    print(f'Running model: {version}')\n",
    "    checkpoint_path = get_checkpoint_path(config, version)\n",
    "    set_environment()\n",
    "\n",
    "    tb_logger = TensorBoardLogger(config.tensorboard_path,name=\"\",version=version,default_hp_metric=False)\n",
    "    \n",
    "    \n",
    "    create_folder(f\"{colab_path}results/{version}\")\n",
    "\n",
    "    save_config(config, version)\n",
    "    \n",
    "    mse_callback = MAE_Callback(tb_logger,checkpoint_path,config,validation,lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
    "    \n",
    "    \n",
    "    trainer = pl.Trainer(callbacks=[mse_callback] + get_cycle_gan_callbacks(checkpoint_path),\n",
    "                         devices=1,\n",
    "                         max_epochs = config.epochs,\n",
    "                         precision = 16, \n",
    "                         num_sanity_val_steps = 1,\n",
    "                         logger = tb_logger,\n",
    "                         log_every_n_steps = config.log_every_n_steps,\n",
    "                         deterministic = False,\n",
    "                         accelerator=accelerator,\n",
    "                         enable_model_summary=False) \n",
    "    \n",
    "\n",
    "    datamodule = DataModule(config, training_batch_size = config.train_batch_size, test_batch_size = config.test_batch_size)\n",
    "    datamodule.setup(\"fit\")\n",
    "    \n",
    "    \n",
    "    if pretrain_path==False:\n",
    "        print(\"no pretraining\")\n",
    "        if config.epochs==1:\n",
    "            model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
    "                           epoch_decay = config.epochs,running_bias=config.running_bias,\n",
    "                           num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
    "        else:\n",
    "            model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
    "                           epoch_decay = config.epochs // 2,running_bias=config.running_bias,\n",
    "                           num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
    "\n",
    "    else:\n",
    "        print(\"using pretrained model with path:\",pretrain_path)\n",
    "        model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
    "                       epoch_decay = config.epochs // 2, running_bias=config.running_bias,\n",
    "                       num_resnet_blocks=config.num_resnet_layer, \n",
    "                       default_nbr_resnet=config.default_nbr_resnet).load_from_checkpoint(pretrain_path)\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "\n",
    "    print('Training finished')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-nYOq2tAfe"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RDSas-G6yYG1"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\" \n",
    "    Training configuration parameters. For model evaluation parameters see\n",
    "    src/configuration.py.\n",
    "    \"\"\"\n",
    "    \n",
    "    scratch_path: str = f'{colab_path}results'\n",
    "    tensorboard_path: str = f'{scratch_path}/'\n",
    "    checkpoint_path: str = f'{scratch_path}/'\n",
    "    config_path: str = f'{scratch_path}/'\n",
    "    \n",
    "    if detrend_data==True:\n",
    "        model_pr_path: str = f\"{colab_path}data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
    "        era5_pr_path: str = f\"{colab_path}data/detrend_pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
    "        model_t_path: str = f\"{colab_path}data/detrend_tas_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
    "        era5_t_path: str = f\"{colab_path}data/detrend_tas_W5E5v2.0_regionbox_1979-2014.nc\"\n",
    "    \n",
    "    if detrend_data==False:\n",
    "        model_pr_path: str = f\"{colab_path}data/pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
    "        era5_pr_path: str = f\"{colab_path}data/pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
    "        model_t_path: str = f\"{colab_path}data/tas_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
    "        era5_t_path: str = f\"{colab_path}data/tas_W5E5v2.0_regionbox_1979-2014.nc\"\n",
    "       \n",
    "\n",
    "    results_path: str = f'{scratch_path}/'\n",
    "    projection_path: str = None\n",
    "\n",
    "    train_start: int = 1979\n",
    "    train_end: int = 2000 #2000 \n",
    "    valid_start: int = 2001 #was 2001\n",
    "    valid_end: int = 2004\n",
    "    test_start: int = 2004\n",
    "    test_end: int = 2014\n",
    "    \n",
    "    model_name: str = 'tibet_gan'\n",
    "\n",
    "    epochs: int = 60 # set to 250 for reproduction\n",
    "    train_batch_size: int = 1\n",
    "    test_batch_size: int = 64\n",
    "    transforms: List = field(default_factory=lambda: ['log', 'normalize_minus1_to_plus1'])\n",
    "    transformations = ['log', 'normalize_minus1_to_plus1']\n",
    "    rescale: bool = False\n",
    "    epsilon: float = 0.001 #0.0001\n",
    "    lazy: bool = False\n",
    "    log_every_n_steps: int = 10 ### was 10\n",
    "    norm_output: bool = True\n",
    "    running_bias: bool = False\n",
    "\n",
    "    #d_lr = 3e-4 # was 2e-4\n",
    "    #g_lr = 1e-4 # was 2e-4\n",
    "    \n",
    "    d_lr = 5e-4 #2e-4\n",
    "    g_lr = 1e-5 #2e-4\n",
    "    \n",
    "    \n",
    "    beta_1 = 0.5\n",
    "    beta_2 = 0.999\n",
    "    epoch_decay = 200\n",
    "    \n",
    "\n",
    "    time = datetime.now().time().strftime(\"%Hh_%Mm_%Ss\")\n",
    "    date = datetime.now().date().strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    default_nbr_resnet=True\n",
    "    num_resnet_layer=6\n",
    "\n",
    "\n",
    "def main():\n",
    "    _ = train_cycle_gan(Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuE3z8TfEMhH"
   },
   "source": [
    "#Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on detrended data: False\n"
     ]
    }
   ],
   "source": [
    "print(\"training on detrended data:\", detrend_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cid_5UwLyttz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on detrended data: False\n",
      "Running model: 2023_03_03_11h_45m_25s\n",
      "using pretrained model with path: bias_gan_t_p/results/2023_03_02_13h_02m_03s/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /dss/dsshome1/0D/ge74xuf2/bias_gan_t_p/results/2023_03_03_11h_45m_25s exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 80 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|â–         | 195/8059 [00:23<15:43,  8.34it/s, loss=2.1, v_num=_25s, g_tot_train_loss_step=7.320, g_A2B_train_loss_step=5.820, g_B2A_train_loss_step=5.040, d_A_train_loss_step=0.0597, d_B_train_loss_step=0.0467]  "
     ]
    }
   ],
   "source": [
    "do_training = True\n",
    "from_skratch = False\n",
    "\n",
    "track_lat_mean = True\n",
    "plt_hist=True\n",
    "\n",
    "runtime_instance = \"2023_03_02_13h_02m_03s\"    \n",
    "\n",
    "print(\"training on detrended data:\", detrend_data)\n",
    "\n",
    "if do_training == True:\n",
    "    accelerator= \"gpu\"\n",
    "\n",
    "    if from_skratch == True:\n",
    "        train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
    "        \n",
    "\n",
    "    if from_skratch == False:\n",
    "        train_cycle_gan(Config(),f\"{colab_path}results/{runtime_instance}/last.ckpt\",validation=True,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommented 0.5 in model.py line 33  --   dis_tot_loss = (loss_real_data + loss_fake_data) #* 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change num_lay = 2 in model.py\n",
    "\n",
    "#class CycleGAN(pl.LightningModule):\n",
    "#self.d_A = init(Discriminator(in_channels = 2, out_channels = 64, num_layers = 2)) #was 3\n",
    "#self.d_B = init(Discriminator(in_channels = 2, out_channels = 64, num_layers = 2)) #was 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au8YMzdenH1w"
   },
   "source": [
    "# Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C07ecZu8qKK"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6I1AxV4Y3Wg"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if do_training==True: \n",
    "    if is_colab==True:\n",
    "        %tensorboard --logdir /content/gdrive/MyDrive/bias_gan/results/{version}/\n",
    "    else:\n",
    "        %tensorboard --logdir /bias_gan/results/{version}/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BBG_ha-qWOj"
   },
   "outputs": [],
   "source": [
    "#if do_training==False: \n",
    "#    if is_colab==True:\n",
    "#        %tensorboard --logdir /content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/\n",
    "#    else:\n",
    "#        %tensorboard --logdir /bias_gan/results/{runtime_instance}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAnl0A4nBRxm"
   },
   "source": [
    "## save images from tensorboard files to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images_for_gif = False\n",
    "\n",
    "\n",
    "def save_tensorboard_images(event_file, outdir):\n",
    "    event_acc = event_accumulator.EventAccumulator(event_file, size_guidance={'images': 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    outdir = pathlib.Path(outdir)\n",
    "    outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for tag in event_acc.Tags()['images']:\n",
    "        events = event_acc.Images(tag)\n",
    "\n",
    "        tag_name = tag.replace('/', '_')\n",
    "        dirpath = outdir / tag_name\n",
    "        dirpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        for index, event in enumerate(events):\n",
    "            s = np.frombuffer(event.encoded_image_string, dtype=np.uint8)\n",
    "            image = cv2.imdecode(s, cv2.IMREAD_COLOR)\n",
    "            #outpath = dirpath / '{:04}.jpg'.format(index) \n",
    "            outpath = dirpath / '{:04}.jpg'.format(index+239)\n",
    "            cv2.imwrite(outpath.as_posix(), image)\n",
    "\n",
    "\n",
    "\n",
    "if save_images_for_gif == True:\n",
    "    folder_path = f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}\"\n",
    "    tensorboard_files = glob.glob(os.path.join(folder_path, 'events.out.tfevents*'))\n",
    "    tensorboard_file = os.path.basename(tensorboard_files[0])\n",
    "    \n",
    "    path_to_event_file = f'/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/{tensorboard_file}'\n",
    "    outdir = f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}\"\n",
    "    save_tensorboard_images(path_to_event_file, outdir)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab==True:\n",
    "    import imageio\n",
    "    import os\n",
    "    from google.colab import files\n",
    "\n",
    "    def create_gif(images_folder, gif_name, duration=0.7):\n",
    "        images = []\n",
    "        filenames = sorted((images_folder).glob(\"*.jpg\"))\n",
    "        for filename in filenames:\n",
    "            images.append(imageio.imread(filename))\n",
    "        imageio.mimsave(gif_name, images, duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_gif_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gif and save to the current directory\n",
    "gif_name = f'/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/histogram_precipitation.gif'\n",
    "images_folder = pathlib.Path(f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/histogram precipitation\")\n",
    "\n",
    "if create_gif_bool == True:\n",
    "    create_gif(images_folder, gif_name)\n",
    "    # show the gif in colab\n",
    "    from IPython.display import Image\n",
    "    with open(gif_name,'rb') as f:\n",
    "        display(Image(data=f.read()))\n",
    "\n",
    "\n",
    "# create gif and save to the current directory\n",
    "gif_name = f'/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/histogram_temperature.gif'\n",
    "images_folder = pathlib.Path(f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/histogram\")\n",
    "\n",
    "if create_gif_bool == True:\n",
    "    create_gif(images_folder, gif_name)\n",
    "    # show the gif in colab\n",
    "    from IPython.display import Image\n",
    "    with open(gif_name,'rb') as f:\n",
    "        display(Image(data=f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gif and save to the current directory\n",
    "gif_name = f'/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/latitudinal_mean_precipitation.gif'\n",
    "images_folder = pathlib.Path(f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/latitudinal_mean precipitation\")\n",
    "\n",
    "if create_gif_bool == True:\n",
    "    create_gif(images_folder, gif_name)\n",
    "    # show the gif in colab\n",
    "    from IPython.display import Image\n",
    "    with open(gif_name,'rb') as f:\n",
    "        display(Image(data=f.read()))\n",
    "\n",
    "\n",
    "# create gif and save to the current directory\n",
    "gif_name = f'/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/latitudinal_mean_temperature.gif'\n",
    "images_folder = pathlib.Path(f\"/content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/latitudinal_mean temperature\")\n",
    "\n",
    "if create_gif_bool == True:\n",
    "    create_gif(images_folder, gif_name)\n",
    "    # show the gif in colab\n",
    "    from IPython.display import Image\n",
    "    with open(gif_name,'rb') as f:\n",
    "        display(Image(data=f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2adJLjPo-15I"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGpAmsXwFzjS"
   },
   "source": [
    "## Run Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeBFJMy3-NSq"
   },
   "outputs": [],
   "source": [
    "if do_training==False: \n",
    "  version_ = runtime_instance\n",
    "else:\n",
    "  version_ = version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab==True and do_training==False:\n",
    "    import json\n",
    "\n",
    "    # specify the path of the config file\n",
    "    config_path = f\"{colab_path}results/{version_}/config_model.json\"\n",
    "\n",
    "    # read the contents of the config file\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # replace the paths in the config object\n",
    "    config['scratch_path'] = Config.scratch_path\n",
    "    config['tensorboard_path'] = Config.tensorboard_path\n",
    "    config['checkpoint_path'] = Config.checkpoint_path\n",
    "    config['config_path'] = Config.config_path\n",
    "    config['model_pr_path'] = Config.model_pr_path\n",
    "    config['era5_pr_path'] = Config.era5_pr_path\n",
    "    config['model_t_path'] = Config.model_t_path\n",
    "    config['era5_t_path'] = Config.era5_t_path\n",
    "    config['results_path'] = Config.results_path\n",
    "\n",
    "    # write the modified config object back to the file\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VuJjIiTjpnf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = f\"{colab_path}results/{version_}/last.ckpt\" \n",
    "config_path = f\"{colab_path}results/{version_}/config_model.json\"\n",
    "\n",
    "\n",
    "data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True, version=version_)\n",
    "\n",
    "test_data, reconstruct_data = data.run()\n",
    "test_data = data.get_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxf0UZB5Komf"
   },
   "source": [
    "# Create reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5OZ8gZ5Luyy"
   },
   "outputs": [],
   "source": [
    "Config_adjusted_trafo = Config\n",
    "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
    "dataset = CycleDataset('train', Config_adjusted_trafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZkFP4HVuJ_H"
   },
   "outputs": [],
   "source": [
    " nbr_reconstruction_examples = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwHZWZGZKz6s"
   },
   "source": [
    "## Define inverse transformation and define forward/backward models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvm--uyQ9__7"
   },
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, generator_model: torch.nn.Module, constrain=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.generator =  generator_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.generator(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uqoma3efKsr_"
   },
   "outputs": [],
   "source": [
    "def inv_transform(data, reference=None):\n",
    "        \"\"\" The output equals ERA5, therefore it needs to be\n",
    "            constraind with respect to it\n",
    "        \"\"\"        \n",
    "        data_prec = data.squeeze(0)[0,:,:]\n",
    "        data_tas = data.squeeze(0)[1,:,:]\n",
    "                \n",
    "        if reference is None:\n",
    "            reference_pr = xr.open_dataset(Config.era5_pr_path).era5_precipitation.sel(\n",
    "                                           time=slice(str(Config.train_start), str(Config.train_end))).values\n",
    "            \n",
    "            reference_t = xr.open_dataset(Config.era5_t_path).tas.sel(\n",
    "                                          time=slice(str(Config.train_start), str(Config.train_end))).values\n",
    "        else:\n",
    "            reference_pr = reference.squeeze(0)[0,:,:]\n",
    "            reference_t = reference.squeeze(0)[1,:,:]\n",
    "            \n",
    "            \n",
    "        if 'log' in Config.transformations:\n",
    "            reference_pr = log_transform(reference_pr, Config.epsilon)\n",
    "\n",
    "        if 'normalize' in Config.transformations:\n",
    "            data = inv_norm_transform(data, reference)\n",
    "\n",
    "        if 'normalize_minus1_to_plus1' in Config.transformations:\n",
    "            data_prec = inv_norm_minus1_to_plus1_transform(data_prec, reference_pr)\n",
    "            data_tas = inv_norm_minus1_to_plus1_transform(data_tas, reference_t)\n",
    "\n",
    "        if 'log' in Config.transformations:\n",
    "            data_prec = inv_log_transform(data_prec, Config.epsilon)\n",
    "        \n",
    "        data[0,0,:,:] = data_prec * 3600*24\n",
    "        data[0,1,:,:] = data_tas\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "ckpt_path = Config.checkpoint_path + f\"{version_}\" +\"/last.ckpt\"\n",
    "\n",
    "model_fw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "model_fw.freeze()\n",
    "model_fw = model_fw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "model_fw = Generator(model_fw.g_B2A, constrain=False)\n",
    "\n",
    "\n",
    "model_bw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "model_bw.freeze()\n",
    "model_bw = model_bw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "model_bw = Generator(model_bw.g_A2B, constrain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tyc4ELg9K5Dq"
   },
   "source": [
    "## reconstruction starting with climate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVaBt7A3K6Sl"
   },
   "outputs": [],
   "source": [
    "for i in range(nbr_reconstruction_examples):\n",
    "    test_data_ = dataset[i]  \n",
    "    \n",
    "    model = test_data_['B'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')).unsqueeze(0)\n",
    "    gan = model_fw(model)\n",
    "    rec = model_bw(gan)\n",
    "\n",
    "    data_model = inv_transform(model.cpu()) \n",
    "    data_gan= inv_transform(gan.cpu())\n",
    "    data_rec = inv_transform(rec.cpu())\n",
    "    \n",
    "    model_pr = data_model.squeeze(0)[0,:,:]\n",
    "    model_t = data_model.squeeze(0)[1,:,:]\n",
    "\n",
    "    gan_pr = data_gan.squeeze()[0,:,:]\n",
    "    gan_t = data_gan.squeeze()[1,:,:]\n",
    "    \n",
    "    rec_pr = data_rec.squeeze()[0,:,:]\n",
    "    rec_t = data_rec.squeeze()[1,:,:]\n",
    "    \n",
    "\n",
    "    print(\"average predicted error in precipitation:\",np.round(torch.sum(abs(model_pr-gan_pr).cpu())/(60*118),5),\"[mm/d]\")\n",
    "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(model_t-gan_t).cpu())/(60*118),0),\"[K]\")\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    cs = ax[0].pcolormesh(model_pr.squeeze().cpu())\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
    "    sm = plt.cm.ScalarMappable(norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
    "    ax[0].set_title(\"climate model data precipitation\")\n",
    "\n",
    "    cs = ax[1].pcolormesh(gan_pr.squeeze().cpu() )#, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
    "    ax[1].set_title(\"generated observation (gan) precipitation\")\n",
    "\n",
    "    cs = ax[2].pcolormesh(rec_pr.squeeze().cpu() ) #, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
    "    ax[2].set_title(\"reconstruction of climate model data precipitation\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    cs = ax[0].pcolormesh(model_t.squeeze().cpu())\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
    "    sm = plt.cm.ScalarMappable(norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
    "    ax[0].set_title(\"climate model data temperature\")\n",
    "\n",
    "    cs = ax[1].pcolormesh(gan_t.squeeze().cpu() )#, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
    "    ax[1].set_title(\"generated observation (gan) temperature\")\n",
    "\n",
    "    cs = ax[2].pcolormesh(rec_t.squeeze().cpu() ) #, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
    "    ax[2].set_title(\"reconstruction of climate model data temperature\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NBbOL6iLC73"
   },
   "source": [
    "## reconstruction starting with observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nbr_reconstruction_examples):\n",
    "    test_data_ = dataset[i]  \n",
    "\n",
    "    obs = test_data_['A'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')).unsqueeze(0)\n",
    "    gan = model_bw(obs)\n",
    "    rec = model_fw(gan)\n",
    "\n",
    "    data_obs = inv_transform(obs.cpu()) \n",
    "    data_gan= inv_transform(gan.cpu())\n",
    "    data_rec = inv_transform(rec.cpu())    \n",
    "    \n",
    "    obs_pr = data_obs.squeeze(0)[0,:,:]\n",
    "    obs_t = data_obs.squeeze(0)[1,:,:]\n",
    "\n",
    "    gan_pr = data_gan.squeeze()[0,:,:]\n",
    "    gan_t = data_gan.squeeze()[1,:,:]\n",
    "    \n",
    "    rec_pr = data_rec.squeeze()[0,:,:]\n",
    "    rec_t = data_rec.squeeze()[1,:,:]\n",
    "\n",
    "    \n",
    "    print(\"average predicted error in precipitation:\",np.round(torch.sum(abs(obs_pr-gan_pr).cpu())/(60*118),5),\"[mm/d]\")\n",
    "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(obs_t-gan_t).cpu())/(60*118),0),\"[K]\")\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    cs = ax[0].pcolormesh(obs_pr.squeeze().cpu())\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
    "    sm = plt.cm.ScalarMappable(norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
    "    ax[0].set_title(\"observation data precipitation\")\n",
    "\n",
    "    cs = ax[1].pcolormesh(gan_pr.squeeze().cpu() )#, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
    "    ax[1].set_title(\"generated climate model data (gan) precipitation\")\n",
    "\n",
    "    cs = ax[2].pcolormesh(rec_pr.squeeze().cpu() ) #, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
    "    ax[2].set_title(\"reconstruction of observation data precipitation\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    cs = ax[0].pcolormesh(obs_t.squeeze().cpu())\n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
    "    sm = plt.cm.ScalarMappable(norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
    "    ax[0].set_title(\"observation data temperature\")\n",
    "\n",
    "    cs = ax[1].pcolormesh(gan_t.squeeze().cpu() )#, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
    "    ax[1].set_title(\"generated climate model data (gan) temperature\")\n",
    "\n",
    "    cs = ax[2].pcolormesh(rec_t.squeeze().cpu() ) #, cmap=\"Blues\")\n",
    "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
    "    ax[2].set_title(\"reconstruction of observation data temperature\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOMdYqIrEBEE"
   },
   "source": [
    "# Plot  **frames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAh6JIg0nCC8"
   },
   "source": [
    "## Plot single frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7NrV7zfnELz"
   },
   "source": [
    "set the chose_day parameter to plot the precipitation on a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdNmJG-jHyGp"
   },
   "outputs": [],
   "source": [
    "#chose_day=10\n",
    "\n",
    "#PlotAnalysis(test_data).single_frames_pr(time_index=chose_day)\n",
    "#PlotAnalysis(test_data).single_frames_pr(projection=\"cyl\",time_index=chose_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PlotAnalysis(test_data).single_frames_t(time_index=chose_day)\n",
    "#PlotAnalysis(test_data).single_frames_t(projection=\"cyl\",time_index=chose_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rInMTAV9t7jZ"
   },
   "source": [
    "## plot of the average test_data for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04wEV8jGnfkx"
   },
   "outputs": [],
   "source": [
    "#PlotAnalysis(test_data).avg_frames(projection=\"cyl\",scale_precip_by = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZrUokXJuHxm"
   },
   "source": [
    "## plot of the average **errors** between era5 & gan / climate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLvmxOQVgsqN"
   },
   "outputs": [],
   "source": [
    "#PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5e8_eN2Ggk7"
   },
   "source": [
    "**TODO**: plot spatial plot - mean Error - also show lands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXihevAlFamY"
   },
   "source": [
    "# Plot **histogram** statistics\n",
    "Precipitation rates averaged over time and longitudes and relative frequency histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9B4JKnll_iR"
   },
   "source": [
    "## histogram no log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfvPYKo3QKg5"
   },
   "source": [
    "Here we plot the histogram over the daily precipitation values in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNlHXpskQVoF"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10, 10),  constrained_layout=True)\n",
    "\n",
    "#PlotAnalysis(test_data).histograms_pr(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAnalysis(test_data).histograms_t(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et2xtAYKmCfn"
   },
   "source": [
    "## histogram log on **density**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYgwpz8CQYYT"
   },
   "source": [
    "Because it is hard to see anything because precipitations over 50 are very rare and thus the 3 plots are right above eachother, we apply the log to the probability desnity to better see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add raw climate model data here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do plot up to 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmVwmg1G3-Fb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
    "\n",
    "PlotAnalysis(test_data).histograms_pr(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True,xlim_end=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAnalysis(test_data).histograms_t(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True,xlim_end=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start 230 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5VbVeqyF92W"
   },
   "source": [
    "## plot histogram log density **differences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyzvlWO2Lsaa"
   },
   "source": [
    "days in the test_data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ4w2of3LT6c"
   },
   "outputs": [],
   "source": [
    "len(getattr(test_data,\"gan\").time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m60e1vv6F-B5"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
    "\n",
    "PlotAnalysis(test_data).histogram_diff_pr(single_plot=False, ax=ax, show_legend=True, annotate=True,xlim_end=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAnalysis(test_data).histogram_diff_t(single_plot=False, ax=ax, show_legend=True, annotate=True,xlim_end=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nolk4FVNloC9"
   },
   "source": [
    "## plot log **precipitation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUlODjL9PuRr"
   },
   "source": [
    "Applying the **log** to the data itself instead of to the amount of points in the bins as in the plot before results in the density to be on one scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wX7CMfFUE-JV"
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
    "#PlotAnalysis(test_data).log_histograms(single_plot=False, ax=ax, show_legend=True, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbqJBrV8O3un"
   },
   "source": [
    "## plot histogram log precipitation differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp7f8K0nO-a1"
   },
   "outputs": [],
   "source": [
    "#PlotAnalysis(test_data).log_histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJEOwVMmFkZp"
   },
   "source": [
    "# Plot **latitudinal** **mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkWfYREj2shn"
   },
   "outputs": [],
   "source": [
    "PlotAnalysis(test_data).latitudinal_mean_pr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAnalysis(test_data).latitudinal_mean_t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BDZR-hows48Z",
    "We_xzajk-9xY",
    "bgA1wp1y-yxZ",
    "ecz59xDYFx7c"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
