{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/bias_gan_t_p/blob/main/code/tas_prec_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3yHWmlizCSY"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pA6IDNyIjKkk"
      },
      "outputs": [],
      "source": [
        "is_colab = True\n",
        "\n",
        "if is_colab==False:\n",
        "    colab_path = \"bias_gan_t_p/\"\n",
        "else:\n",
        "    colab_path = \"/content/gdrive/MyDrive/bias_gan_t_p/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UtBBY2Vx4kVx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1a70b59-f492-4790-ebed-f71ffb08743f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ngpu_info = !nvidia-smi\\ngpu_info = '\\n'.join(gpu_info)\\nif gpu_info.find('failed') >= 0:\\n  print('Not connected to a GPU')\\nelse:\\n  print(gpu_info)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvWGv1NOjKkl",
        "outputId": "0a8604d4-e113-487a-95bf-33603aba8310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "if is_colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPOM7rdsjKkl",
        "outputId": "faf3c08c-d2e6-4f5a-f78b-858906624feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bias_gan_t_p'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 61 (delta 8), reused 9 (delta 4), pack-reused 41\u001b[K\n",
            "Unpacking objects: 100% (61/61), 4.61 MiB | 3.62 MiB/s, done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.8/dist-packages (1.6.2)\n",
            "Requirement already satisfied: numpy>1.13.3 in /usr/local/lib/python3.8/dist-packages (from cftime) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "if is_colab == True:\n",
        "    !git clone https://github.com/aim56009/bias_gan_t_p.git\n",
        "    !pip install cftime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yg_fJ3Fi0rzt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "!pip install basemap\n",
        "!pip install importlib-metadata==4.0.1\n",
        "!pip install xarray==0.18.1\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DgFt3kE0jKkm"
      },
      "outputs": [],
      "source": [
        "if is_colab == False:\n",
        "    import os\n",
        "    os.chdir('/dss/dsshome1/0D/ge74xuf2/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ctpYd5RO0GJ3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xarray as xr\n",
        "import torch\n",
        "import json\n",
        "import glob\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import argparse\n",
        "import pathlib\n",
        "import cv2\n",
        "import matplotlib\n",
        "\n",
        "\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "#from Bias_GAN.code.src.model import CycleGAN, Generator, DataModule                     \n",
        "from bias_gan_t_p.code.src.model import CycleGAN, Generator#, DataModule                     \n",
        "\n",
        "#from Bias_GAN.code.src.data import TestData, CycleDataset\n",
        "from bias_gan_t_p.code.src.utils import get_version, set_environment, get_checkpoint_path, save_config, log_transform, inv_norm_transform, inv_log_transform, inv_norm_minus1_to_plus1_transform, norm_minus1_to_plus1_transform \n",
        "from bias_gan_t_p.code.src.plots import PlotAnalysis, plot_basemap\n",
        "from bias_gan_t_p.code.src.callbacks import get_cycle_gan_callbacks, MAE_Callback\n",
        "from bias_gan_t_p.code.src.inference import Inference, EvaluateCheckpoints, create_folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3sTfmwpSezN"
      },
      "source": [
        "# Data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TogZq-xfjmC5"
      },
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 config,\n",
        "                 training_batch_size: int = 4,\n",
        "                 test_batch_size: int = 64):\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.training_batch_size = training_batch_size\n",
        "        self.test_batch_size = test_batch_size\n",
        "\n",
        "    def setup(self, stage: str = None):\n",
        "\n",
        "        if stage == 'fit' or stage is None:\n",
        "            self.train = CycleDataset('train', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        "        if stage == 'test':\n",
        "            self.test = CycleDataset('test', self.config)\n",
        "            self.valid = CycleDataset('valid', self.config)\n",
        "\n",
        " \n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train,\n",
        "                         batch_size=self.training_batch_size,\n",
        "                         shuffle=True,\n",
        "                         num_workers=80,\n",
        "                         pin_memory=True)\n",
        "\n",
        "\n",
        "    def val_dataloader  (self):\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=10,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "    def test_dataloader (self):\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.test_batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=10,\n",
        "                          pin_memory=True)\n",
        "\n",
        "\n",
        "def show_image(image):\n",
        "    plt.imshow((image.squeeze()))\n",
        "\n",
        "\n",
        "def get_random_sample(dataset):\n",
        "    return dataset[np.random.randint(0, len(dataset))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mIzh0Kl2Sg9U"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import cftime\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TestData():\n",
        "    \n",
        "    era5: xr.DataArray\n",
        "    gan: xr.DataArray\n",
        "    climate_model: xr.DataArray = None\n",
        "    uuid: str = None\n",
        "    model = None\n",
        "    \n",
        "\n",
        "    def model_name_definition(self, key):\n",
        "        dict = {\n",
        "            'era5': 'ERA5',\n",
        "            'gan': 'GAN (unconstrained)',\n",
        "            'climate_model': 'Climate model',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "\n",
        "    def colors(self, key):\n",
        "        dict = {\n",
        "            'era5': 'k',\n",
        "            'gan': 'brown',\n",
        "            'climate_model': 'r',\n",
        "        }\n",
        "        return dict[key]\n",
        "\n",
        "        \n",
        "    def convert_units(self):\n",
        "        \"\"\" from mm/s to mm/d\"\"\"\n",
        "        climate_model_pr = self.climate_model.precipitation*3600*24\n",
        "        era5_pr = self.era5.precipitation*3600*24\n",
        "        gan_pr = self.gan.precipitation*3600*24\n",
        "        \n",
        "        \n",
        "        self.era5['precipitation'] = era5_pr\n",
        "        self.climate_model['precipitation'] = climate_model_pr\n",
        "        self.gan['precipitation'] = gan_pr\n",
        "    \n",
        "    def crop_test_period(self):\n",
        "        print('')\n",
        "        print(f'Test set period: {self.gan.tas.time[0].values} - {self.gan.tas.time[-1].values}')\n",
        "        \n",
        "        climate_model_pr = self.climate_model.precipitation.sel(time=slice(self.gan.tas.time[0], self.gan.tas.time[-1]))\n",
        "        climate_model_t = self.climate_model.tas.sel(time=slice(self.gan.tas.time[0], self.gan.tas.time[-1]))\n",
        "        era5_pr = self.era5.precipitation.sel(time=slice(self.gan.tas.time[0], self.gan.tas.time[-1]))\n",
        "        era5_t = self.era5.tas.sel(time=slice(self.gan.tas.time[0], self.gan.tas.time[-1]))\n",
        "        \n",
        "        self.era5['precipitation'] = era5_pr\n",
        "        self.climate_model['precipitation'] = climate_model_pr\n",
        "        \n",
        "        self.era5['tas'] = era5_t\n",
        "        self.climate_model['tas'] = climate_model_t\n",
        "        \n",
        "    def show_mean(self):\n",
        "        print('')\n",
        "        print(f'Mean precipitation [mm/d]:')\n",
        "        print(f'ERA5: {self.era5_pr.mean().values:2.3f}')\n",
        "        print(f'Climate Model: {self.climate_model_pr.mean().values:2.3f}')\n",
        "        print(f'GAN:  {self.gan.precipitation.mean().values:2.3f}')\n",
        "        \n",
        "        print('')\n",
        "        print(f'Mean temperature [K]:')\n",
        "        print(f'ERA5: {self.era5_t.mean().values:2.3f}')\n",
        "        print(f'Climate Model: {self.climate_model_t.mean().values:2.3f}')\n",
        "        print(f'GAN:  {self.gan.tas.mean().values:2.3f}')\n",
        "\n",
        "\n",
        "\n",
        "class CycleDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, stage, config, epsilon=0.001): #=0.0001):\n",
        "        \"\"\" \n",
        "            stage: train, valid, test\n",
        "        \"\"\"\n",
        "        self.transforms = config.transforms\n",
        "        self.epsilon = epsilon\n",
        "        self.config = config\n",
        "\n",
        "        if config.lazy:\n",
        "            self.cache = False\n",
        "            self.chunks = {'time': 1}\n",
        "        else:#this\n",
        "            self.cache = True\n",
        "            self.chunks = None\n",
        "        \n",
        "        self.splits = {\n",
        "                \"train\": [str(config.train_start), str(config.train_end)],\n",
        "                \"valid\": [str(config.valid_start), str(config.valid_end)],\n",
        "                \"test\":  [str(config.test_start), str(config.test_end)],\n",
        "        }\n",
        "\n",
        "        self.stage = stage\n",
        "        \n",
        "        self.climate_model = self.load_climate_model_data()\n",
        "        climate_model_reference = self.load_climate_model_data(is_reference=True)\n",
        "        \n",
        "        self.era5 = self.load_era5_data()\n",
        "        era5_reference = self.load_era5_data(is_reference=True)\n",
        "\n",
        "        self.num_samples = len(self.era5.tas.time.values)\n",
        "        \n",
        "        self.era5 = self.apply_transforms(self.era5, era5_reference)\n",
        "        self.climate_model = self.apply_transforms(self.climate_model, climate_model_reference)\n",
        "\n",
        "\n",
        "\n",
        "    def load_climate_model_data(self, is_reference=False):\n",
        "        \"\"\" Y-domain samples \"\"\"\n",
        "\n",
        "        climate_model_pr = xr.open_dataset(self.config.model_pr_path, cache=self.cache, chunks=self.chunks)\n",
        "        climate_model_pr =  climate_model_pr.precipitation\n",
        "                \n",
        "        climate_model_t = xr.open_dataset(self.config.model_t_path, cache=self.cache, chunks=self.chunks)\n",
        "        climate_model_t =  climate_model_t.tas\n",
        "                \n",
        "\n",
        "        if not self.config.lazy:\n",
        "            climate_model_pr = climate_model_pr.load()\n",
        "            climate_model_t = climate_model_t.load()\n",
        "\n",
        "        if is_reference:\n",
        "            climate_model_pr = climate_model_pr.sel(time=slice(self.splits['train'][0], self.splits['train'][1]))\n",
        "            climate_model_t = climate_model_t.sel(time=slice(self.splits['train'][0], self.splits['train'][1]))\n",
        "        else:\n",
        "            climate_model_pr = climate_model_pr.sel(time=slice(self.splits[self.stage][0],self.splits[self.stage][1]))\n",
        "            climate_model_t = climate_model_t.sel(time=slice(self.splits[self.stage][0],self.splits[self.stage][1]))\n",
        "        \n",
        "        \n",
        "        climate_model = xr.Dataset({'precipitation': climate_model_pr, 'tas': climate_model_t})\n",
        "\n",
        "        return climate_model\n",
        "\n",
        "\n",
        "    def load_era5_data(self, is_reference=False):\n",
        "        \"\"\" X-domain samples \"\"\"\n",
        "\n",
        "        era5_pr = xr.open_dataset(self.config.era5_pr_path,cache=self.cache, chunks=self.chunks).era5_precipitation\n",
        "        era5_t = xr.open_dataset(self.config.era5_t_path,cache=self.cache, chunks=self.chunks).tas\n",
        "\n",
        "        if not self.config.lazy:\n",
        "            era5_pr = era5_pr.load()\n",
        "            era5_t = era5_t.load()\n",
        "\n",
        "        if is_reference:\n",
        "            era5_pr = era5_pr.sel(time=slice(self.splits['train'][0],self.splits['train'][1]))\n",
        "            era5_t = era5_t.sel(time=slice(self.splits['train'][0],self.splits['train'][1]))\n",
        "\n",
        "        else:\n",
        "            era5_pr = era5_pr.sel(time=slice(self.splits[self.stage][0], self.splits[self.stage][1]))\n",
        "            era5_t = era5_t.sel(time=slice(self.splits[self.stage][0], self.splits[self.stage][1]))    \n",
        "        \n",
        "        era5 = xr.Dataset({'precipitation': era5_pr, 'tas': era5_t})\n",
        "\n",
        "        return era5\n",
        "        \n",
        "\n",
        "    def apply_transforms(self, data, data_ref):\n",
        "        \n",
        "        data_prec = data.precipitation\n",
        "        data_tas = data.tas\n",
        "                \n",
        "        data_prec_ref = data_ref.precipitation\n",
        "        data_tas_ref = data_ref.tas\n",
        "        \n",
        "                \n",
        "        if 'log' in self.transforms:\n",
        "            data_prec = log_transform(data_prec, self.epsilon)\n",
        "            data_prec_ref = log_transform(data_prec_ref, self.epsilon)\n",
        "\n",
        "        if 'normalize' in self.transforms:\n",
        "            data = norm_transform(data, data_ref)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in self.transforms:\n",
        "            data_prec = norm_minus1_to_plus1_transform(data_prec, data_prec_ref)\n",
        "            data_tas = norm_minus1_to_plus1_transform(data_tas, data_tas_ref)\n",
        "        \n",
        "        data_ref['precipitation'] = data_prec_ref\n",
        "        \n",
        "        data['precipitation'] = data_prec\n",
        "        data['tas'] = data_tas\n",
        "        \n",
        "                \n",
        "        return data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        x_p = torch.from_numpy(self.era5.precipitation.isel(time=index).values).float().unsqueeze(0)\n",
        "        x_t = torch.from_numpy(self.era5.tas.isel(time=index).values).float().unsqueeze(0)\n",
        "        x = torch.cat((x_p, x_t), dim=0)\n",
        "        \n",
        "        y_p = torch.from_numpy(self.climate_model.precipitation.isel(time=index).values).float().unsqueeze(0)\n",
        "        y_t = torch.from_numpy(self.climate_model.tas.isel(time=index).values).float().unsqueeze(0)\n",
        "        y = torch.cat((y_p, y_t), dim=0)\n",
        "        \n",
        "        #print(\"check for nan:\",torch.sum(x),torch.sum(y))\n",
        "        \n",
        "        sample = {'A': x, 'B': y}\n",
        "        \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G_tIaaJWjKko"
      },
      "outputs": [],
      "source": [
        "#Config_adjusted_trafo = Config\n",
        "#nbr_reconstruction_examples = 1\n",
        "#Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "#dataset = CycleDataset('train', Config_adjusted_trafo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tP4VzlHijKko"
      },
      "outputs": [],
      "source": [
        "#datamodule = DataModule(Config, training_batch_size = Config.train_batch_size, test_batch_size = Config.test_batch_size)\n",
        "#datamodule.setup(\"fit\")\n",
        "#train_loader = datamodule.train_dataloader()\n",
        "\n",
        "#for batch_idx, data in enumerate(train_loader):\n",
        "#    data[\"A\"]\n",
        "#    data[\"B\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HHb0dnst_Lpq"
      },
      "outputs": [],
      "source": [
        "track_lat_mean = True\n",
        "plt_hist=True\n",
        "accelerator= \"gpu\"\n",
        "\n",
        "#train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZR-hows48Z"
      },
      "source": [
        "# Main training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtINdQOafvRG"
      },
      "source": [
        "## define MAE callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KpchPItBC6E6"
      },
      "outputs": [],
      "source": [
        "class MAE_Callback(Callback):\n",
        "    def __init__(self,logger,checkpoint_path,config, validation=True, lat_mean=False, plt_hist=False):\n",
        "        self.MAE_list_pr = []\n",
        "        self.MAE_list_t = []\n",
        "        self.logger = logger\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.config = config\n",
        "        self.version = get_version(config.date,config.time)\n",
        "        self.validation = validation\n",
        "        self.lat_mean = lat_mean\n",
        "        self.plt_hist = plt_hist\n",
        "        \n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        checkpoint_files = glob.glob(str(self.checkpoint_path) + '/*.ckpt')\n",
        "        if not checkpoint_files:\n",
        "            test_data_ = None\n",
        "        else:\n",
        "            last_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "            data = EvaluateCheckpoints(checkpoint_path=last_checkpoint, config_path=self.config.config_path + self.version + \"/config_model.json\", save_model=True,validation=self.validation, version=self.version)\n",
        "            _, reconstruction_data = data.run()\n",
        "            test_data_ = data.get_test_data()\n",
        "\n",
        "\n",
        "        if test_data_ is None or not test_data_:\n",
        "            print(\"No test data available.\")\n",
        "            return\n",
        "\n",
        "        gan_data = getattr(test_data_, 'gan')\n",
        "        era5_data = getattr(test_data_, \"era5\")\n",
        "        \n",
        "        bias_pr = gan_data.precipitation.mean('time') - era5_data.precipitation.mean('time') \n",
        "        print(\"GAN-OBS precipitation\",f\" \\t \\t MAE: {abs(bias_pr).values.mean():2.3f} [mm/d]\")\n",
        "        self.MAE_list_pr.append(abs(bias_pr).values.mean())\n",
        "        print(\"MAE_list precipitation:\",self.MAE_list_pr)\n",
        "        self.log('MAE p', abs(bias_pr).values.mean())\n",
        "        print(\"\")\n",
        "        bias_t = gan_data.tas.mean('time') - era5_data.tas.mean('time') \n",
        "        print(\"GAN-OBS tas\",f\" \\t \\t MAE: {abs(bias_t).values.mean():2.3f} [K]\")\n",
        "        self.MAE_list_t.append(abs(bias_t).values.mean())\n",
        "        print(\"MAE_list tas:\",self.MAE_list_t)\n",
        "        self.log('MAE t', abs(bias_t).values.mean())\n",
        "        print(\"\")\n",
        "\n",
        "        if test_data_ is not None and self.lat_mean==True:\n",
        "            data_era5_pr = era5_data.precipitation.mean(dim=(\"longitude\", \"time\"))\n",
        "            data_era5_t = era5_data.tas.mean(dim=(\"lon\", \"time\"))\n",
        "            \n",
        "            data_gan_pr= gan_data.precipitation.mean(dim=(\"longitude\", \"time\"))\n",
        "            data_gan_t= gan_data.tas.mean(dim=(\"longitude\", \"time\"))\n",
        "            \n",
        "            plt.figure()\n",
        "            \n",
        "            plt.plot(data_gan_pr.latitude, data_gan_pr.data,\n",
        "                      label=\"gan precipitation\",\n",
        "                      alpha=0.9,\n",
        "                      linestyle='-',\n",
        "                      linewidth=2,\n",
        "                      color=\"red\")\n",
        "            \n",
        "            plt.plot(data_era5_pr.latitude, data_era5_pr.data,\n",
        "                      label=\"era5 precipitation\",\n",
        "                      alpha=1,\n",
        "                      linestyle='--',\n",
        "                      linewidth=2,\n",
        "                      color=\"black\")\n",
        "            \n",
        "            #plt.ylim(0,3)\n",
        "            plt.xlim(25,58)\n",
        "            plt.xlabel('Latitude')\n",
        "            plt.ylabel('Mean precipitation [mm/d]')\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')  \n",
        "            \n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im = Image.open(buf)\n",
        "            img = torchvision.transforms.ToTensor()(im)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"latitudinal_mean precipitation\", img, trainer.current_epoch)\n",
        "            \n",
        "            \n",
        "            ###\n",
        "            plt.figure()\n",
        "            \n",
        "            plt.plot(data_gan_t.latitude, data_gan_t.data,\n",
        "                      label=\"gan temperature\",\n",
        "                      alpha=0.9,\n",
        "                      linestyle='-',\n",
        "                      linewidth=2,\n",
        "                      color=\"red\")\n",
        "            \n",
        "            plt.plot(data_era5_t.lat, data_era5_t.data,\n",
        "                      label=\"era5 temperature\",\n",
        "                      alpha=1,\n",
        "                      linestyle='--',\n",
        "                      linewidth=2,\n",
        "                      color=\"black\")\n",
        "            \n",
        "            #plt.ylim(0,3)\n",
        "            plt.xlim(25,58)\n",
        "            plt.xlabel('Latitude')\n",
        "            plt.ylabel('Mean temperature [K]')\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')\n",
        "            #plt.show()\n",
        "            ###\n",
        "            \n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im = Image.open(buf)\n",
        "            img = torchvision.transforms.ToTensor()(im)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"latitudinal_mean temperature\", img, trainer.current_epoch)\n",
        "\n",
        "        if test_data_ is not None and self.plt_hist==True:\n",
        "            data_gan_pr = getattr(test_data_, \"gan\").precipitation.values.flatten()\n",
        "            data_era5_pr = getattr(test_data_, \"era5\").precipitation.values.flatten()\n",
        "            plt.figure()\n",
        "            _ = plt.hist(data_gan_pr,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"gan\",\n",
        "                        alpha=0.9,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"red\")\n",
        "            \n",
        "            _ = plt.hist(data_era5_pr,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"era5\",\n",
        "                        alpha=1,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"black\")\n",
        "\n",
        "            plt.xlabel('Precipitation [mm/d]')\n",
        "            plt.ylabel('Histogram')\n",
        "            #plt.xlim(0,400)\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')\n",
        "\n",
        "            #plt.show()\n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im_ = Image.open(buf)\n",
        "            img_ = torchvision.transforms.ToTensor()(im_)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"histogram precipitation\", img_, trainer.current_epoch)\n",
        "            \n",
        "            \n",
        "            data_gan_t = getattr(test_data_, \"gan\").tas.values.flatten()\n",
        "            data_era5_t = getattr(test_data_, \"era5\").tas.values.flatten()\n",
        "            plt.figure()\n",
        "            _ = plt.hist(data_gan_t,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"gan\",\n",
        "                        alpha=0.9,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"red\")\n",
        "            \n",
        "            _ = plt.hist(data_era5_t,\n",
        "                        bins=100,\n",
        "                        histtype='step',\n",
        "                        log=True,\n",
        "                        label=\"era5\",\n",
        "                        alpha=1,\n",
        "                        density=True,\n",
        "                        linewidth=2,\n",
        "                        color=\"black\")\n",
        "\n",
        "            plt.xlabel('Temperature [K]')\n",
        "            plt.ylabel('Histogram')\n",
        "            #plt.xlim(0,400)\n",
        "            plt.grid()\n",
        "            plt.legend(loc='upper right')\n",
        "\n",
        "            #plt.show()\n",
        "            buf = BytesIO()\n",
        "            plt.savefig(buf, format='png')\n",
        "            buf.seek(0)\n",
        "            im_ = Image.open(buf)\n",
        "            img_ = torchvision.transforms.ToTensor()(im_)\n",
        "            \n",
        "            self.logger.experiment.add_image(f\"histogram\", img_, trainer.current_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO0_lUBIfzaH"
      },
      "source": [
        "## Train Cycle GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "efWHPrX2Ck9K"
      },
      "outputs": [],
      "source": [
        "def train_cycle_gan(config, pretrain_path=False,validation=True,track_lat_mean=False,plt_hist=False ):\n",
        "    \"\"\" Main routing to train the Cycle GAN \"\"\"\n",
        "\n",
        "    config = Config()\n",
        "    global version\n",
        "    version = get_version(config.date,config.time)\n",
        "    print(f'Running model: {version}')\n",
        "    checkpoint_path = get_checkpoint_path(config, version)\n",
        "    set_environment()\n",
        "\n",
        "    tb_logger = TensorBoardLogger(config.tensorboard_path,name=\"\",version=version,default_hp_metric=False)\n",
        "    \n",
        "    \n",
        "    create_folder(f\"{colab_path}results/{version}\")\n",
        "\n",
        "    save_config(config, version)\n",
        "    \n",
        "    mse_callback = MAE_Callback(tb_logger,checkpoint_path,config,validation,lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "    \n",
        "    \n",
        "    trainer = pl.Trainer(callbacks=[mse_callback] + get_cycle_gan_callbacks(checkpoint_path),\n",
        "                         devices=1,\n",
        "                         #gpus = 1,\n",
        "                         max_epochs = config.epochs,\n",
        "                         precision = 16, \n",
        "                         num_sanity_val_steps = 1,\n",
        "                         logger = tb_logger,\n",
        "                         log_every_n_steps = config.log_every_n_steps,\n",
        "                         deterministic = False,\n",
        "                         accelerator=accelerator,\n",
        "                         enable_model_summary=False) \n",
        "    \n",
        "\n",
        "    datamodule = DataModule(config, training_batch_size = config.train_batch_size, test_batch_size = config.test_batch_size)\n",
        "    datamodule.setup(\"fit\")\n",
        "    \n",
        "    \n",
        "    if pretrain_path==False:\n",
        "        print(\"no pretraining\")\n",
        "        if config.epochs==1:\n",
        "            model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                           epoch_decay = config.epochs,running_bias=config.running_bias,\n",
        "                           num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
        "        else:\n",
        "            model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                           epoch_decay = config.epochs // 2,running_bias=config.running_bias,\n",
        "                           num_resnet_blocks=config.num_resnet_layer, default_nbr_resnet=config.default_nbr_resnet)\n",
        "\n",
        "    else:\n",
        "        print(\"using pretrained model with path:\",pretrain_path)\n",
        "        model = CycleGAN(d_lr=config.d_lr, g_lr=config.g_lr, beta_1=config.beta_1, beta_2=config.beta_2,\n",
        "                       epoch_decay = config.epochs // 2, running_bias=config.running_bias,\n",
        "                       num_resnet_blocks=config.num_resnet_layer, \n",
        "                       default_nbr_resnet=config.default_nbr_resnet).load_from_checkpoint(pretrain_path)\n",
        "\n",
        "    trainer.fit(model, datamodule)\n",
        "\n",
        "    print('Training finished')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq-nYOq2tAfe"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RDSas-G6yYG1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\" \n",
        "    Training configuration parameters. For model evaluation parameters see\n",
        "    src/configuration.py.\n",
        "    \"\"\"\n",
        "    \n",
        "    scratch_path: str = f'{colab_path}results'\n",
        "    tensorboard_path: str = f'{scratch_path}/'\n",
        "    checkpoint_path: str = f'{scratch_path}/'\n",
        "    config_path: str = f'{scratch_path}/'\n",
        "    \n",
        "    model_pr_path: str = f\"{colab_path}data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_pr_path: str = f\"{colab_path}data/detrend_pr_W5E5v2.0_regionbox_era5_1979-2014.nc\"\n",
        "    model_t_path: str = f\"{colab_path}data/detrend_tas_gfdl-esm4_historical_regionbox_1979-2014.nc\"\n",
        "    era5_t_path: str = f\"{colab_path}data/detrend_tas_W5E5v2.0_regionbox_1979-2014.nc\"\n",
        "       \n",
        "\n",
        "    results_path: str = f'{scratch_path}/'\n",
        "    projection_path: str = None\n",
        "\n",
        "    train_start: int = 1979\n",
        "    train_end: int = 2000 #2000 \n",
        "    valid_start: int = 2004 #was 2001\n",
        "    valid_end: int = 2004\n",
        "    test_start: int = 2004\n",
        "    test_end: int = 2014\n",
        "    \n",
        "    model_name: str = 'tibet_gan'\n",
        "\n",
        "    epochs: int = 100 # set to 250 for reproduction\n",
        "    train_batch_size: int = 1\n",
        "    test_batch_size: int = 64\n",
        "    transforms: List = field(default_factory=lambda: ['log', 'normalize_minus1_to_plus1'])\n",
        "    transformations = ['log', 'normalize_minus1_to_plus1']\n",
        "    rescale: bool = False\n",
        "    epsilon: float = 0.001 #0.0001\n",
        "    lazy: bool = False\n",
        "    log_every_n_steps: int = 10 ### was 10\n",
        "    norm_output: bool = True\n",
        "    running_bias: bool = False\n",
        "\n",
        "    d_lr = 2e-4\n",
        "    g_lr = 2e-4\n",
        "    beta_1 = 0.5\n",
        "    beta_2 = 0.999\n",
        "    epoch_decay = 200\n",
        "    \n",
        "\n",
        "    time = datetime.now().time().strftime(\"%Hh_%Mm_%Ss\")\n",
        "    date = datetime.now().date().strftime(\"%Y_%m_%d\")\n",
        "    \n",
        "    default_nbr_resnet=True\n",
        "    num_resnet_layer=6\n",
        "\n",
        "\n",
        "def main():\n",
        "    _ = train_cycle_gan(Config())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuE3z8TfEMhH"
      },
      "source": [
        "#Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Cid_5UwLyttz",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "do_training = False\n",
        "from_skratch = True\n",
        "\n",
        "track_lat_mean = True\n",
        "plt_hist=True\n",
        "\n",
        "runtime_instance = \"2023_02_21_11h_35m_00s\"\n",
        "\n",
        "if do_training == True:\n",
        "    accelerator= \"gpu\"\n",
        "\n",
        "    if from_skratch == True:\n",
        "        train_cycle_gan(Config(),validation=False,track_lat_mean=track_lat_mean,plt_hist=plt_hist)\n",
        "        \n",
        "\n",
        "    if from_skratch == False:\n",
        "        train_cycle_gan(Config(),f\"{colab_path}results/{runtime_instance}/last.ckpt\",validation=True,track_lat_mean=track_lat_mean,plt_hist=plt_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au8YMzdenH1w"
      },
      "source": [
        "# Tensorboard logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-C07ecZu8qKK"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T6I1AxV4Y3Wg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee2a35aa-7a19-4f40-9497-a3a9009640fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nif do_training==True: \\n    if is_colab==True:\\n        %tensorboard --logdir /content/gdrive/MyDrive/bias_gan_t_p/results/{version}/\\n    else:\\n        %tensorboard --logdir /bias_gan/results/{version}/\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\"\"\"\n",
        "if do_training==True: \n",
        "    if is_colab==True:\n",
        "        %tensorboard --logdir /content/gdrive/MyDrive/bias_gan_t_p/results/{version}/\n",
        "    else:\n",
        "        %tensorboard --logdir /bias_gan/results/{version}/\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BBG_ha-qWOj"
      },
      "outputs": [],
      "source": [
        "if do_training==False: \n",
        "    if is_colab==True:\n",
        "        %tensorboard --logdir /content/gdrive/MyDrive/bias_gan_t_p/results/{runtime_instance}/\n",
        "    else:\n",
        "        %tensorboard --logdir /bias_gan/results/{runtime_instance}/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAnl0A4nBRxm"
      },
      "source": [
        "## save images from tensorboard files to drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGDAuCARcGl"
      },
      "source": [
        "## get MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sB1qvReJWBZl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c28f257-2cf4-47bf-f0e2-f9192c65af1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nConfig_adjusted_trafo = Config\\nConfig_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\\nlen_training_dataset = len(CycleDataset('train', Config_adjusted_trafo))\\nlen_valid_dataset = len(CycleDataset('valid', Config_adjusted_trafo))\\nlen_test_dataset = len(CycleDataset('test', Config_adjusted_trafo))\\n\\nlen_training_dataset, len_valid_dataset, len_test_dataset\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\"\"\"\n",
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "len_training_dataset = len(CycleDataset('train', Config_adjusted_trafo))\n",
        "len_valid_dataset = len(CycleDataset('valid', Config_adjusted_trafo))\n",
        "len_test_dataset = len(CycleDataset('test', Config_adjusted_trafo))\n",
        "\n",
        "len_training_dataset, len_valid_dataset, len_test_dataset\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2adJLjPo-15I"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGpAmsXwFzjS"
      },
      "source": [
        "## Run Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LeBFJMy3-NSq"
      },
      "outputs": [],
      "source": [
        "if do_training==False: \n",
        "  version_ = runtime_instance\n",
        "else:\n",
        "  version_ = version\n",
        "\n",
        "\n",
        "checkpoint_path = f\"{colab_path}results/{version_}/last.ckpt\" \n",
        "config_path = f\"{colab_path}results/{version_}/config_model.json\"\n",
        "\n",
        "data = EvaluateCheckpoints(checkpoint_path=checkpoint_path, config_path=config_path, save_model=True, version=version_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xr.open_dataset(Config.model_pr_path)"
      ],
      "metadata": {
        "id": "cht7YTPypDQj",
        "outputId": "a6d7f8ae-6433-4156-b000-054e53333bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<xarray.Dataset>\n",
              "Dimensions:        (latitude: 60, longitude: 118, time: 13149)\n",
              "Coordinates:\n",
              "  * time           (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2014-12-31\n",
              "  * latitude       (latitude) float64 55.75 55.25 54.75 ... 27.25 26.75 26.25\n",
              "  * longitude      (longitude) float64 46.25 46.75 47.25 ... 103.8 104.2 104.8\n",
              "Data variables:\n",
              "    precipitation  (time, latitude, longitude) float32 ..."
            ],
            "text/html": [
              "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
              "<defs>\n",
              "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
              "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
              "</symbol>\n",
              "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
              "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
              "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
              "</symbol>\n",
              "</defs>\n",
              "</svg>\n",
              "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
              " *\n",
              " */\n",
              "\n",
              ":root {\n",
              "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
              "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
              "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
              "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
              "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
              "  --xr-background-color: var(--jp-layout-color0, white);\n",
              "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
              "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
              "}\n",
              "\n",
              "html[theme=dark],\n",
              "body.vscode-dark {\n",
              "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
              "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
              "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
              "  --xr-border-color: #1F1F1F;\n",
              "  --xr-disabled-color: #515151;\n",
              "  --xr-background-color: #111111;\n",
              "  --xr-background-color-row-even: #111111;\n",
              "  --xr-background-color-row-odd: #313131;\n",
              "}\n",
              "\n",
              ".xr-wrap {\n",
              "  display: block;\n",
              "  min-width: 300px;\n",
              "  max-width: 700px;\n",
              "}\n",
              "\n",
              ".xr-text-repr-fallback {\n",
              "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-header {\n",
              "  padding-top: 6px;\n",
              "  padding-bottom: 6px;\n",
              "  margin-bottom: 4px;\n",
              "  border-bottom: solid 1px var(--xr-border-color);\n",
              "}\n",
              "\n",
              ".xr-header > div,\n",
              ".xr-header > ul {\n",
              "  display: inline;\n",
              "  margin-top: 0;\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-obj-type,\n",
              ".xr-array-name {\n",
              "  margin-left: 2px;\n",
              "  margin-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-obj-type {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-sections {\n",
              "  padding-left: 0 !important;\n",
              "  display: grid;\n",
              "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
              "}\n",
              "\n",
              ".xr-section-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-section-item input {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-item input + label {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label {\n",
              "  cursor: pointer;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-item input:enabled + label:hover {\n",
              "  color: var(--xr-font-color0);\n",
              "}\n",
              "\n",
              ".xr-section-summary {\n",
              "  grid-column: 1;\n",
              "  color: var(--xr-font-color2);\n",
              "  font-weight: 500;\n",
              "}\n",
              "\n",
              ".xr-section-summary > span {\n",
              "  display: inline-block;\n",
              "  padding-left: 0.5em;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label {\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in + label:before {\n",
              "  display: inline-block;\n",
              "  content: '►';\n",
              "  font-size: 11px;\n",
              "  width: 15px;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:disabled + label:before {\n",
              "  color: var(--xr-disabled-color);\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label:before {\n",
              "  content: '▼';\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked + label > span {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-section-summary,\n",
              ".xr-section-inline-details {\n",
              "  padding-top: 4px;\n",
              "  padding-bottom: 4px;\n",
              "}\n",
              "\n",
              ".xr-section-inline-details {\n",
              "  grid-column: 2 / -1;\n",
              "}\n",
              "\n",
              ".xr-section-details {\n",
              "  display: none;\n",
              "  grid-column: 1 / -1;\n",
              "  margin-bottom: 5px;\n",
              "}\n",
              "\n",
              ".xr-section-summary-in:checked ~ .xr-section-details {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-array-wrap {\n",
              "  grid-column: 1 / -1;\n",
              "  display: grid;\n",
              "  grid-template-columns: 20px auto;\n",
              "}\n",
              "\n",
              ".xr-array-wrap > label {\n",
              "  grid-column: 1;\n",
              "  vertical-align: top;\n",
              "}\n",
              "\n",
              ".xr-preview {\n",
              "  color: var(--xr-font-color3);\n",
              "}\n",
              "\n",
              ".xr-array-preview,\n",
              ".xr-array-data {\n",
              "  padding: 0 5px !important;\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-array-data,\n",
              ".xr-array-in:checked ~ .xr-array-preview {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              ".xr-array-in:checked ~ .xr-array-data,\n",
              ".xr-array-preview {\n",
              "  display: inline-block;\n",
              "}\n",
              "\n",
              ".xr-dim-list {\n",
              "  display: inline-block !important;\n",
              "  list-style: none;\n",
              "  padding: 0 !important;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list li {\n",
              "  display: inline-block;\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "}\n",
              "\n",
              ".xr-dim-list:before {\n",
              "  content: '(';\n",
              "}\n",
              "\n",
              ".xr-dim-list:after {\n",
              "  content: ')';\n",
              "}\n",
              "\n",
              ".xr-dim-list li:not(:last-child):after {\n",
              "  content: ',';\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-has-index {\n",
              "  font-weight: bold;\n",
              "}\n",
              "\n",
              ".xr-var-list,\n",
              ".xr-var-item {\n",
              "  display: contents;\n",
              "}\n",
              "\n",
              ".xr-var-item > div,\n",
              ".xr-var-item label,\n",
              ".xr-var-item > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-even);\n",
              "  margin-bottom: 0;\n",
              "}\n",
              "\n",
              ".xr-var-item > .xr-var-name:hover span {\n",
              "  padding-right: 5px;\n",
              "}\n",
              "\n",
              ".xr-var-list > li:nth-child(odd) > div,\n",
              ".xr-var-list > li:nth-child(odd) > label,\n",
              ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
              "  background-color: var(--xr-background-color-row-odd);\n",
              "}\n",
              "\n",
              ".xr-var-name {\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-var-dims {\n",
              "  grid-column: 2;\n",
              "}\n",
              "\n",
              ".xr-var-dtype {\n",
              "  grid-column: 3;\n",
              "  text-align: right;\n",
              "  color: var(--xr-font-color2);\n",
              "}\n",
              "\n",
              ".xr-var-preview {\n",
              "  grid-column: 4;\n",
              "}\n",
              "\n",
              ".xr-var-name,\n",
              ".xr-var-dims,\n",
              ".xr-var-dtype,\n",
              ".xr-preview,\n",
              ".xr-attrs dt {\n",
              "  white-space: nowrap;\n",
              "  overflow: hidden;\n",
              "  text-overflow: ellipsis;\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-var-name:hover,\n",
              ".xr-var-dims:hover,\n",
              ".xr-var-dtype:hover,\n",
              ".xr-attrs dt:hover {\n",
              "  overflow: visible;\n",
              "  width: auto;\n",
              "  z-index: 1;\n",
              "}\n",
              "\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  display: none;\n",
              "  background-color: var(--xr-background-color) !important;\n",
              "  padding-bottom: 5px !important;\n",
              "}\n",
              "\n",
              ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
              ".xr-var-data-in:checked ~ .xr-var-data {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              ".xr-var-data > table {\n",
              "  float: right;\n",
              "}\n",
              "\n",
              ".xr-var-name span,\n",
              ".xr-var-data,\n",
              ".xr-attrs {\n",
              "  padding-left: 25px !important;\n",
              "}\n",
              "\n",
              ".xr-attrs,\n",
              ".xr-var-attrs,\n",
              ".xr-var-data {\n",
              "  grid-column: 1 / -1;\n",
              "}\n",
              "\n",
              "dl.xr-attrs {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  display: grid;\n",
              "  grid-template-columns: 125px auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt,\n",
              ".xr-attrs dd {\n",
              "  padding: 0;\n",
              "  margin: 0;\n",
              "  float: left;\n",
              "  padding-right: 10px;\n",
              "  width: auto;\n",
              "}\n",
              "\n",
              ".xr-attrs dt {\n",
              "  font-weight: normal;\n",
              "  grid-column: 1;\n",
              "}\n",
              "\n",
              ".xr-attrs dt:hover span {\n",
              "  display: inline-block;\n",
              "  background: var(--xr-background-color);\n",
              "  padding-right: 10px;\n",
              "}\n",
              "\n",
              ".xr-attrs dd {\n",
              "  grid-column: 2;\n",
              "  white-space: pre-wrap;\n",
              "  word-break: break-all;\n",
              "}\n",
              "\n",
              ".xr-icon-database,\n",
              ".xr-icon-file-text2 {\n",
              "  display: inline-block;\n",
              "  vertical-align: middle;\n",
              "  width: 1em;\n",
              "  height: 1.5em !important;\n",
              "  stroke-width: 0;\n",
              "  stroke: currentColor;\n",
              "  fill: currentColor;\n",
              "}\n",
              "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
              "Dimensions:        (latitude: 60, longitude: 118, time: 13149)\n",
              "Coordinates:\n",
              "  * time           (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2014-12-31\n",
              "  * latitude       (latitude) float64 55.75 55.25 54.75 ... 27.25 26.75 26.25\n",
              "  * longitude      (longitude) float64 46.25 46.75 47.25 ... 103.8 104.2 104.8\n",
              "Data variables:\n",
              "    precipitation  (time, latitude, longitude) float32 ...</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-6ddf1823-3399-437f-a236-490f88a46d01' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-6ddf1823-3399-437f-a236-490f88a46d01' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>latitude</span>: 60</li><li><span class='xr-has-index'>longitude</span>: 118</li><li><span class='xr-has-index'>time</span>: 13149</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-18187fca-6efa-4f74-bb5e-bfd72d5a23a6' class='xr-section-summary-in' type='checkbox'  checked><label for='section-18187fca-6efa-4f74-bb5e-bfd72d5a23a6' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1979-01-01 ... 2014-12-31</div><input id='attrs-2a14b53e-bd45-4684-a752-7106301128c6' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2a14b53e-bd45-4684-a752-7106301128c6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2b251ecf-6711-45dd-a19b-4166351df2ca' class='xr-var-data-in' type='checkbox'><label for='data-2b251ecf-6711-45dd-a19b-4166351df2ca' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1979-01-01T00:00:00.000000000&#x27;, &#x27;1979-01-02T00:00:00.000000000&#x27;,\n",
              "       &#x27;1979-01-03T00:00:00.000000000&#x27;, ..., &#x27;2014-12-29T00:00:00.000000000&#x27;,\n",
              "       &#x27;2014-12-30T00:00:00.000000000&#x27;, &#x27;2014-12-31T00:00:00.000000000&#x27;],\n",
              "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>55.75 55.25 54.75 ... 26.75 26.25</div><input id='attrs-e7186aab-7c16-4ba3-8ea4-296c8f5a7e32' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e7186aab-7c16-4ba3-8ea4-296c8f5a7e32' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-53d84da6-37a6-4af0-b9eb-0b930744b50c' class='xr-var-data-in' type='checkbox'><label for='data-53d84da6-37a6-4af0-b9eb-0b930744b50c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([55.75, 55.25, 54.75, 54.25, 53.75, 53.25, 52.75, 52.25, 51.75, 51.25,\n",
              "       50.75, 50.25, 49.75, 49.25, 48.75, 48.25, 47.75, 47.25, 46.75, 46.25,\n",
              "       45.75, 45.25, 44.75, 44.25, 43.75, 43.25, 42.75, 42.25, 41.75, 41.25,\n",
              "       40.75, 40.25, 39.75, 39.25, 38.75, 38.25, 37.75, 37.25, 36.75, 36.25,\n",
              "       35.75, 35.25, 34.75, 34.25, 33.75, 33.25, 32.75, 32.25, 31.75, 31.25,\n",
              "       30.75, 30.25, 29.75, 29.25, 28.75, 28.25, 27.75, 27.25, 26.75, 26.25])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>46.25 46.75 47.25 ... 104.2 104.8</div><input id='attrs-e3c4e78e-d379-4bae-9c00-caeff0c98792' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e3c4e78e-d379-4bae-9c00-caeff0c98792' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-65d3a71a-652b-4b37-ba10-194b8e4e2b62' class='xr-var-data-in' type='checkbox'><label for='data-65d3a71a-652b-4b37-ba10-194b8e4e2b62' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([ 46.25,  46.75,  47.25,  47.75,  48.25,  48.75,  49.25,  49.75,  50.25,\n",
              "        50.75,  51.25,  51.75,  52.25,  52.75,  53.25,  53.75,  54.25,  54.75,\n",
              "        55.25,  55.75,  56.25,  56.75,  57.25,  57.75,  58.25,  58.75,  59.25,\n",
              "        59.75,  60.25,  60.75,  61.25,  61.75,  62.25,  62.75,  63.25,  63.75,\n",
              "        64.25,  64.75,  65.25,  65.75,  66.25,  66.75,  67.25,  67.75,  68.25,\n",
              "        68.75,  69.25,  69.75,  70.25,  70.75,  71.25,  71.75,  72.25,  72.75,\n",
              "        73.25,  73.75,  74.25,  74.75,  75.25,  75.75,  76.25,  76.75,  77.25,\n",
              "        77.75,  78.25,  78.75,  79.25,  79.75,  80.25,  80.75,  81.25,  81.75,\n",
              "        82.25,  82.75,  83.25,  83.75,  84.25,  84.75,  85.25,  85.75,  86.25,\n",
              "        86.75,  87.25,  87.75,  88.25,  88.75,  89.25,  89.75,  90.25,  90.75,\n",
              "        91.25,  91.75,  92.25,  92.75,  93.25,  93.75,  94.25,  94.75,  95.25,\n",
              "        95.75,  96.25,  96.75,  97.25,  97.75,  98.25,  98.75,  99.25,  99.75,\n",
              "       100.25, 100.75, 101.25, 101.75, 102.25, 102.75, 103.25, 103.75, 104.25,\n",
              "       104.75])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7e393428-a5b5-49b4-8269-2bb3dec3baf5' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7e393428-a5b5-49b4-8269-2bb3dec3baf5' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>precipitation</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-dc9e310b-4f85-4498-9a1e-54d18e0a4a08' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-dc9e310b-4f85-4498-9a1e-54d18e0a4a08' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8958ad1d-7371-414e-a8a2-55b209e0eb48' class='xr-var-data-in' type='checkbox'><label for='data-8958ad1d-7371-414e-a8a2-55b209e0eb48' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>precipitation_flux</dd><dt><span>long_name :</span></dt><dd>Precipitation</dd><dt><span>units :</span></dt><dd>kg m-2 s-1</dd></dl></div><div class='xr-var-data'><pre>[93094920 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f7d225af-4e67-4e0c-8a99-5fc9a507c57b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-f7d225af-4e67-4e0c-8a99-5fc9a507c57b' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2VuJjIiTjpnf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdb5512a-9af4-4a6b-a5c9-76a7bb1c5a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint 1 / 1:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/content/bias_gan_t_p/data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c9b370c831b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bias_gan_t_p/code/src/inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_checkpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Checkpoint {self.checkpoint_idx} / {self.num_checkpoints}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mreconstruct_model_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bias_gan_t_p/code/src/inference.py\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         inf = Inference(self.config,\n\u001b[0m\u001b[1;32m    384\u001b[0m                         \u001b[0mconstrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                         \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bias_gan_t_p/code/src/inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, constrain, validation, projection, projection_path, max_num_inference_steps)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_pr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_t_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         store = NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         )\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# ensure file doesn't get overriden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/content/bias_gan_t_p/data/detrend_pr_gfdl-esm4_historical_regionbox_1979-2014.nc'"
          ]
        }
      ],
      "source": [
        "test_data, reconstruct_data = data.run()\n",
        "test_data = data.get_test_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxf0UZB5Komf"
      },
      "source": [
        "# Create reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5OZ8gZ5Luyy"
      },
      "outputs": [],
      "source": [
        "Config_adjusted_trafo = Config\n",
        "Config_adjusted_trafo.transforms = Config_adjusted_trafo.transformations\n",
        "dataset = CycleDataset('train', Config_adjusted_trafo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZkFP4HVuJ_H"
      },
      "outputs": [],
      "source": [
        " nbr_reconstruction_examples = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwHZWZGZKz6s"
      },
      "source": [
        "## Define inverse transformation and define forward/backward models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvm--uyQ9__7"
      },
      "outputs": [],
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, generator_model: torch.nn.Module, constrain=True):\n",
        "        super(Generator, self).__init__()\n",
        "        self.generator =  generator_model\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.generator(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqoma3efKsr_"
      },
      "outputs": [],
      "source": [
        "def inv_transform(data, reference=None):\n",
        "        \"\"\" The output equals ERA5, therefore it needs to be\n",
        "            constraind with respect to it\n",
        "        \"\"\"\n",
        "        data_prec = data.squeeze(0)[0,:,:]\n",
        "        data_tas = data.squeeze(0)[1,:,:]\n",
        "        \n",
        "        if reference is None:\n",
        "            reference_pr = xr.open_dataset(Config.era5_pr_path).era5_precipitation.sel(\n",
        "                                           time=slice(str(Config.train_start), str(Config.train_end))).values\n",
        "            \n",
        "            reference_t = xr.open_dataset(Config.era5_t_path).tas.sel(\n",
        "                                          time=slice(str(Config.train_start), str(Config.train_end))).values\n",
        "        else:\n",
        "            reference_pr = reference.squeeze(0)[0,:,:]\n",
        "            reference_t = reference.squeeze(0)[1,:,:]\n",
        "        if 'log' in Config.transformations:\n",
        "            reference_pr = log_transform(reference_pr, Config.epsilon)\n",
        "\n",
        "        if 'normalize' in Config.transformations:\n",
        "            data = inv_norm_transform(data, reference)\n",
        "\n",
        "        if 'normalize_minus1_to_plus1' in Config.transformations:\n",
        "            data_prec = inv_norm_minus1_to_plus1_transform(data_prec, reference_pr)\n",
        "            data_tas = inv_norm_minus1_to_plus1_transform(data_tas, reference_t)\n",
        "\n",
        "        if 'log' in Config.transformations:\n",
        "            data_prec = inv_log_transform(data_prec, Config.epsilon)\n",
        "            \n",
        "        data[0,0,:,:] = data_prec\n",
        "        data[0,1,:,:] = data_tas\n",
        "\n",
        "        return data\n",
        "    \n",
        "\n",
        "ckpt_path = Config.checkpoint_path + f\"{version_}\" +\"/last.ckpt\"\n",
        "\n",
        "model_fw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_fw.freeze()\n",
        "model_fw = model_fw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_fw = Generator(model_fw.g_B2A, constrain=False)\n",
        "\n",
        "\n",
        "model_bw = CycleGAN().load_from_checkpoint(checkpoint_path=ckpt_path)\n",
        "model_bw.freeze()\n",
        "model_bw = model_bw.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "model_bw = Generator(model_bw.g_A2B, constrain=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyc4ELg9K5Dq"
      },
      "source": [
        "## reconstruction starting with climate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVaBt7A3K6Sl"
      },
      "outputs": [],
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    model = test_data_['B'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')).unsqueeze(0)\n",
        "    gan = model_fw(model)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    data_model = inv_transform(model.cpu()) \n",
        "    data_gan= inv_transform(gan.cpu())\n",
        "    data_rec = inv_transform(rec.cpu())\n",
        "    \n",
        "    \n",
        "    model_pr = data_model.squeeze(0)[0,:,:]\n",
        "    model_t = data_model.squeeze(0)[1,:,:]\n",
        "\n",
        "    gan_pr = data_gan.squeeze()[0,:,:]\n",
        "    gan_t = data_gan.squeeze()[1,:,:]\n",
        "    \n",
        "    rec_pr = data_rec.squeeze()[0,:,:]\n",
        "    rec_t = data_rec.squeeze()[1,:,:]\n",
        "\n",
        "\n",
        "    print(\"average predicted error in precipitation:\",np.round(torch.sum(abs(model_pr-gan_pr).cpu())/(60*118),5),\"[K]\")\n",
        "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(model_t-gan_t).cpu())/(60*118),0),\"[K]\")\n",
        "\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(model_pr.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"climate model data precipitation\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(gan_pr.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated observation (gan) precipitation\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(rec_pr.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of climate model data precipitation\")\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(model_t.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"climate model data temperature\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(gan_t.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated observation (gan) temperature\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(rec_t.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of climate model data temperature\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NBbOL6iLC73"
      },
      "source": [
        "## reconstruction starting with observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94REU6gyjKkq"
      },
      "outputs": [],
      "source": [
        "for i in range(nbr_reconstruction_examples):\n",
        "    test_data_ = dataset[i]  \n",
        "\n",
        "    obs = test_data_['A'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')).unsqueeze(0)\n",
        "    gan = model_fw(model)\n",
        "    rec = model_bw(gan)\n",
        "\n",
        "    data_obs = inv_transform(obs.cpu()) \n",
        "    data_gan= inv_transform(gan.cpu())\n",
        "    data_rec = inv_transform(rec.cpu())    \n",
        "    \n",
        "    obs_pr = data_obs.squeeze(0)[0,:,:]\n",
        "    obs_t = data_obs.squeeze(0)[1,:,:]\n",
        "\n",
        "    gan_pr = data_gan.squeeze()[0,:,:]\n",
        "    gan_t = data_gan.squeeze()[1,:,:]\n",
        "    \n",
        "    rec_pr = data_rec.squeeze()[0,:,:]\n",
        "    rec_t = data_rec.squeeze()[1,:,:]\n",
        "\n",
        "    \n",
        "    print(\"average predicted error in precipitation:\",np.round(torch.sum(abs(obs_pr-gan_pr).cpu())/(60*118),5),\"[K]\")\n",
        "    print(\"average predicted error in temperature:\",np.round(torch.sum(abs(obs_t-gan_t).cpu())/(60*118),0),\"[K]\")\n",
        "\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(obs_pr.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"observation data precipitation\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(gan_pr.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated climate model data (gan) precipitation\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(rec_pr.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of observation data precipitation\")\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    cs = ax[0].pcolormesh(obs_t.squeeze().cpu())\n",
        "    norm = matplotlib.colors.Normalize(vmin=0, vmax=20)\n",
        "    sm = plt.cm.ScalarMappable(norm=norm)\n",
        "    sm.set_array([])\n",
        "\n",
        "    fig.colorbar(cs, ax=ax[0], extend='max')\n",
        "    ax[0].set_title(\"observation data temperature\")\n",
        "\n",
        "    cs = ax[1].pcolormesh(gan_t.squeeze().cpu() )#, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[1], extend='max')\n",
        "    ax[1].set_title(\"generated climate model data (gan) temperature\")\n",
        "\n",
        "    cs = ax[2].pcolormesh(rec_t.squeeze().cpu() ) #, cmap=\"Blues\")\n",
        "    fig.colorbar(cs, ax=ax[2], extend='max')\n",
        "    ax[2].set_title(\"reconstruction of observation data temperature\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOMdYqIrEBEE"
      },
      "source": [
        "# Plot  **frames**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAh6JIg0nCC8"
      },
      "source": [
        "## Plot single frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7NrV7zfnELz"
      },
      "source": [
        "set the chose_day parameter to plot the precipitation on a specific day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdNmJG-jHyGp"
      },
      "outputs": [],
      "source": [
        "chose_day=10\n",
        "\n",
        "PlotAnalysis(test_data).single_frames_pr(time_index=chose_day)\n",
        "PlotAnalysis(test_data).single_frames_pr(projection=\"cyl\",time_index=chose_day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2UuGMvXjKkr"
      },
      "outputs": [],
      "source": [
        "PlotAnalysis(test_data).single_frames_t(time_index=chose_day)\n",
        "PlotAnalysis(test_data).single_frames_t(projection=\"cyl\",time_index=chose_day)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rInMTAV9t7jZ"
      },
      "source": [
        "## plot of the average test_data for each data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04wEV8jGnfkx"
      },
      "outputs": [],
      "source": [
        "#PlotAnalysis(test_data).avg_frames(projection=\"cyl\",scale_precip_by = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrUokXJuHxm"
      },
      "source": [
        "## plot of the average **errors** between era5 & gan / climate_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLvmxOQVgsqN"
      },
      "outputs": [],
      "source": [
        "#PlotAnalysis(test_data).avg_frames_abs_err(projection=\"cyl\", scale_precip_by = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5e8_eN2Ggk7"
      },
      "source": [
        "**TODO**: plot spatial plot - mean Error - also show lands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXihevAlFamY"
      },
      "source": [
        "# Plot **histogram** statistics\n",
        "Precipitation rates averaged over time and longitudes and relative frequency histograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9B4JKnll_iR"
      },
      "source": [
        "## histogram no log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfvPYKo3QKg5"
      },
      "source": [
        "Here we plot the histogram over the daily precipitation values in the test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNlHXpskQVoF"
      },
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(1,1,figsize=(4, 4),  constrained_layout=True)\n",
        "\n",
        "#PlotAnalysis(test_data).histograms_pr(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91hCOwRzjKkr"
      },
      "outputs": [],
      "source": [
        "#PlotAnalysis(test_data).histograms_t(single_plot=False, ax=ax, show_legend=True, annotate=True,log=False,xlim_end=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2xtAYKmCfn"
      },
      "source": [
        "## histogram log on **density**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYgwpz8CQYYT"
      },
      "source": [
        "Because it is hard to see anything because precipitations over 50 are very rare and thus the 3 plots are right above eachother, we apply the log to the probability desnity to better see the differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmVwmg1G3-Fb"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histograms_pr(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lSGOs1tjKkr"
      },
      "outputs": [],
      "source": [
        "PlotAnalysis(test_data).histograms_t(single_plot=False, ax=ax, show_legend=True, annotate=True,log=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5VbVeqyF92W"
      },
      "source": [
        "## plot histogram log density **differences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyzvlWO2Lsaa"
      },
      "source": [
        "days in the test_data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ4w2of3LT6c"
      },
      "outputs": [],
      "source": [
        "len(getattr(test_data,\"gan\").time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m60e1vv6F-B5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "\n",
        "PlotAnalysis(test_data).histogram_diff_pr(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCPn1bmKjKks"
      },
      "outputs": [],
      "source": [
        "PlotAnalysis(test_data).histogram_diff_t(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nolk4FVNloC9"
      },
      "source": [
        "## plot log **precipitation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUlODjL9PuRr"
      },
      "source": [
        "Applying the **log** to the data itself instead of to the amount of points in the bins as in the plot before results in the density to be on one scale:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX7CMfFUE-JV"
      },
      "outputs": [],
      "source": [
        "#fig, ax = plt.subplots(1,1,figsize=(6, 6),  constrained_layout=True)\n",
        "#PlotAnalysis(test_data).log_histograms(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbqJBrV8O3un"
      },
      "source": [
        "## plot histogram log precipitation differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp7f8K0nO-a1"
      },
      "outputs": [],
      "source": [
        "#PlotAnalysis(test_data).log_histogram_diff(single_plot=False, ax=ax, show_legend=True, annotate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJEOwVMmFkZp"
      },
      "source": [
        "# Plot **latitudinal** **mean**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkWfYREj2shn"
      },
      "outputs": [],
      "source": [
        "PlotAnalysis(test_data).latitudinal_mean_pr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZey4a0cjKks"
      },
      "outputs": [],
      "source": [
        "PlotAnalysis(test_data).latitudinal_mean_t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsCCr9WujKks"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BDZR-hows48Z",
        "We_xzajk-9xY",
        "bgA1wp1y-yxZ",
        "ecz59xDYFx7c"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}